# Hand Gesture Recognition for Robot Car Navigation

This project involves using **MediaPipe** and the **Google Hand Landmark Model** for hand gesture recognition to control an arm robot car. The recognized hand gestures (up, down, left, right, advance, and back) are mapped to specific movement commands for the robot car, enabling intuitive and real-time navigation.

![Hand Gesture Recognition](https://github.com/user-attachments/assets/447f93a0-946d-4367-8afc-2388db628aa1)
 <!-- Replace with the actual image URL -->

## Table of Contents
- [Live Demo](#live-demo)
- [Introduction](#introduction)
- [Features](#features)
- [Technologies Used](#technologies-used)
- [Setup Instructions](#setup-instructions)
- [Usage](#usage)
- [Results](#results)

## Live Demo
You can view the detailed LinkedIn post related to this project [here](https://www.linkedin.com/embed/feed/update/urn:li:ugcPost:7273964578198233089).


## Introduction
Hand Gesture Recognition allows users to control a robotic arm car by using predefined hand gestures. The integration of **MediaPipe** and the **Google Landmark Model** enables real-time recognition of gestures with high accuracy. 

**Supported Gestures**:
- **Up**: Moves the robot car forward.
- **Down**: Moves the robot car backward.
- **Left**: Turns the robot car left.
- **Right**: Turns the robot car right.
- **Advance**: Advances the robotic arm.
- **Back**: Retracts the robotic arm.

## Features
- Real-time hand gesture recognition using **MediaPipe**.
- Navigation and control of an armed robot car using intuitive gestures.
- Accurate detection using the **Google Hand Landmark Model**.
- Easy to set up and extend for more gestures or robot commands.

## Technologies Used
- **MediaPipe** for hand landmark detection.
- **Google Hand Landmark Model** for gesture recognition.
- **Python** as the main programming language.
- **OpenCV** for image processing and real-time video analysis.

## Setup Instructions
1. Clone this repository:
   ```bash
   git clone https://github.com/kishore-github1/hand-gesture-robot-car.git
2. Run app.py

## Results
Here are some examples of how the hand gesture recognition system performs:

### Gesture Examples
- **Up Gesture (Arm Up)**
  ![Screenshot 2024-10-23 134322](https://github.com/user-attachments/assets/77800b17-8f57-445d-b8e0-066cc9e20adf)
 <!-- Replace with the actual image URL -->
  
- **Down Gesture (Arm Dowm)**
  ![Screenshot 2024-10-23 135047](https://github.com/user-attachments/assets/10f39857-8deb-47f6-b53d-10131da2552e)
 <!-- Replace with the actual image URL -->

- **Left Gesture (Turn Left)**
  ![Screenshot 2024-10-23 134141](https://github.com/user-attachments/assets/80d59b5b-858e-422f-ac7f-ee859044e129)
 <!-- Replace with the actual image URL -->

- **Right Gesture (Turn Right)**
  ![Screenshot 2024-10-23 134120](https://github.com/user-attachments/assets/abe10c0d-e2b5-40a5-b109-814d6a98e6f4)
 <!-- Replace with the actual image URL -->

- **Advance Gesture (Move front)**
  ![Screenshot 2024-10-23 134007](https://github.com/user-attachments/assets/7ce7855f-b285-4e1d-a24d-77a9d2136776)
 <!-- Replace with the actual image URL -->

- **Back Gesture (Move back)**
  ![Screenshot 2024-10-23 134038](https://github.com/user-attachments/assets/4f033b0d-1a1e-4fa0-a287-48d1900d905e)
 <!-- Replace with the actual image URL -->

### Robot car
- ![WhatsApp Image 2024-10-23 at 14 21 51_82e3850f](https://github.com/user-attachments/assets/c684309b-5acc-4276-b57d-a2d4304373f5)

